p8105\_hw3\_jz3036
================
Junyuan Zheng (jz3036)
2018-10-10

-   Import necessary packages.

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────────── tidyverse 1.2.1 ──

    ## ✔ ggplot2 3.0.0     ✔ purrr   0.2.5
    ## ✔ tibble  1.4.2     ✔ dplyr   0.7.6
    ## ✔ tidyr   0.8.1     ✔ stringr 1.3.1
    ## ✔ readr   1.1.1     ✔ forcats 0.3.0

    ## ── Conflicts ────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
#library(readxl)
```

Problem 1
=========

-   Import the raw data for Problem 1.

``` r
library(p8105.datasets)
data(brfss_smart2010)
```

-   Data manipulation:

``` r
data_p1 = 
  janitor::clean_names(brfss_smart2010) %>%
  filter(., topic == 'Overall Health') %>%
  filter(., response == 'Poor' | response == 'Fair' | response == 'Good' | response == 'Very good' | response == 'Excellent') %>%
  mutate(., response = factor(response, levels = str_c(c("Excellent", "Very good", "Good", "Fair", "Poor"))))
```

-   Q1 In 2002, which states were observed at 7 locations?

``` r
data_p1_q1 = 
  filter(data_p1, year == '2002') %>% 
  group_by(., locationabbr) %>% 
  summarize(., n_loc = n_distinct(locationdesc)) %>% 
  filter(., n_loc == 7)
data_p1_q1
```

    ## # A tibble: 3 x 2
    ##   locationabbr n_loc
    ##   <chr>        <int>
    ## 1 CT               7
    ## 2 FL               7
    ## 3 NC               7

CT, FL, and NC were observed at 7 locations.

-   Q2 Make a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010.

``` r
data_p1 %>% 
  group_by(., year, locationabbr) %>% 
  summarize(., n_loc = n_distinct(locationdesc)) %>% 
  ggplot(aes(x = year, y = n_loc, color = locationabbr)) +
    geom_point() + geom_line() + 
    theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5)) +
    labs(y = 'number of loc', color = 'states', title = 'spaghetti plot')
```

![](p8105_hw3_jz3036_files/figure-markdown_github/p1_q2-1.png)

-   Q3 Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.

``` r
data_p1 %>%
  filter(., year=='2002' | year=='2006' | year=='2010', response=='Excellent') %>% 
  group_by(., year) %>% 
  summarize(., mean = mean(data_value, na.rm = TRUE), SD = sd(data_value, na.rm = TRUE))
```

    ## # A tibble: 3 x 3
    ##    year  mean    SD
    ##   <int> <dbl> <dbl>
    ## 1  2002  24.0  4.64
    ## 2  2006  22.4  4.10
    ## 3  2010  21.5  4.25

-   Q4 For each year and state, compute the average proportion in each response category (taking the average across locations in a state).

``` r
data_p1_q4_1 = 
  group_by(data_p1, year, locationabbr) %>% 
  summarize(., n_loc = n_distinct(locationdesc))

data_p1_q4_2 =
  group_by(data_p1, year, locationabbr, response) %>%
  summarize(., mean_sum = sum(data_value))

data_p1_q4 = left_join(data_p1_q4_2, data_p1_q4_1, by = c('year'='year', 'locationabbr'='locationabbr'))

data_p1_q4 = mutate(data_p1_q4, avg_prop = mean_sum/n_loc)
head(data_p1_q4)
```

    ## # A tibble: 6 x 6
    ## # Groups:   year, locationabbr [2]
    ##    year locationabbr response  mean_sum n_loc avg_prop
    ##   <int> <chr>        <fct>        <dbl> <int>    <dbl>
    ## 1  2002 AK           Excellent     27.9     1     27.9
    ## 2  2002 AK           Very good     33.7     1     33.7
    ## 3  2002 AK           Good          23.8     1     23.8
    ## 4  2002 AK           Fair           8.6     1      8.6
    ## 5  2002 AK           Poor           5.9     1      5.9
    ## 6  2002 AL           Excellent     18.5     1     18.5

-   Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time.

``` r
ggplot(data_p1_q4, aes(x = year, y = avg_prop, color = locationabbr)) +
    geom_point() + geom_line() +
    facet_grid(. ~ response) +
    theme(legend.position = "right", plot.title = element_text(hjust = 0.5),
          axis.text.x = element_text(angle=90)) +
    labs(y = 'avg_prop', color = 'states', title = 'state-level averages over time')
```

    ## Warning: Removed 21 rows containing missing values (geom_point).

    ## Warning: Removed 1 rows containing missing values (geom_path).

![](p8105_hw3_jz3036_files/figure-markdown_github/p1_q4_2-1.png)

Problem 2
=========

-   Import the raw data for Problem 2.

``` r
library(p8105.datasets)
data(instacart)
data_p2 = instacart
```

-   write a short description of the dataset, noting the size and structure of the data, describing some key variables, and giving illstrative examples of observations.

-   This is a subset of a dataset containing online purchase information for each order. The dataset we are using contains 1384617 rows or purchase of goods, and 15 variables for each purchase.
-   The variables can be roughly separated into three parts: cumtomer info, goods info, and time info. Variables that could potientially provides useful infomation include the reordered info, order time of the week and the day, and the aisle info.
-   For example, the plot below told us people tend to order yogurt on Sunday more, less on the middle of the week.

``` r
data_p2 %>%
  filter(., aisle == 'yogurt') %>% 
  group_by(., order_dow) %>% 
  summarize(., n = n()) %>% 
  ggplot(., aes(x = order_dow, y = n)) +
    geom_point() + geom_line() +
    labs(y = '# of orders', x = 'day of a week', title = 'yogurt order trend')
```

![](p8105_hw3_jz3036_files/figure-markdown_github/p2_example-1.png)

-   Q1 How many aisles are there, and which aisles are the most items ordered from?
